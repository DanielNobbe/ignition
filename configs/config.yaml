defaults:
  - base/base
  - defaults/defaults
  - _self_

name: mri_seg_v0
batch_size: 10 # train batch size
eval_batch_size: 10 # evaluation batch size
learning_rate: 2.0e-4 # learning rate
num_workers: 16 # number of subprocesses to use for data loading
max_epochs: 1000 # number of maximum epochs
use_amp: false # use AMP (Automatic Mixed Precision)

log_every_iters: 1
eval_every_epochs: 5 # evaluate every n epochs
num_classes: 12

backend: nccl  # or nccl
engine_type: monai # or monai or ignite
roi_size: [192, 192, 64]
spacing: [1.0, 1.0, 3.0]
model:
  type: monai # model type, torchvision or monai
  _target_: monai.networks.nets.SegResNetDS
  spatial_dims: 3 # number of spatial dimensions, 2 for 2D, 3 for 3D
  init_filters: 32 # initial number of filters
  in_channels: 1 # number of input channels, 1 for grayscale
  out_channels: ${num_classes} # number of output channels
  # dropout_prob: 0.2 # dropout probability, 0.2 is good default
  blocks_down: [1, 2, 2, 2, 2, 4] # default
  norm: 'INSTANCE_NVFUSER'
  dsdepth: 4
post_transforms:
  train:
    _target_: ignition.data.monai.DSGetFirstd
    keys: ['pred', 'label']
  val:
    _target_: monai.transforms.Compose
    transforms:
      - _target_: monai.transforms.Activationsd
        keys: ['pred']  # keys to apply the activation to
        softmax: true
      - _target_: monai.transforms.AsDiscreted
        keys: ['pred']  # keys to apply the discretization to
        argmax: true  # apply argmax to the predictions
        to_onehot: ${num_classes}  # convert to one-hot encoding
        include_background: true  # include background class in the discretization
      - _target_: monai.transforms.AsDiscreted
        keys: ['label']  # keys to apply the discretization to
        argmax: false  # apply argmax to the predictions
        to_onehot: ${num_classes}  # convert to one-hot encoding
        include_background: true  # include background class in the discretization

dataset:
  type: MonaiSegmentationFolder # dataset type
  images_dir: /ignition/example/dataset/images # images path
  labels_dir: /ignition/example/dataset/labels # labels path
  subset_size: null # use all samples, set to a number between 0.0 and 1.0 to use a subset of the dataset
  val_size: 0.2  # fixed validation split
  cache_mode: lmdb # cache mode, can be 'memory' of 'lmdb'
  cache_dir: ${oc.env:TMPDIR, /home/user}/ignition_lmdb_cache # directory to store lm
  orig_labels:   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
  target_labels: [0, 0, 1, 2, 0, 3, 4, 5, 6, 7,  8,  9, 10, 11,  0]
  transforms:
    train:
      - type: MapLabelValue # to exclude specified labels by mapping them to background
        orig_labels:   ${dataset.orig_labels}
        target_labels: ${dataset.target_labels}
      - type: EnsureChannelFirst
        channel_dim: no_channel  # to automatically add channel dimension if not present
      - type: SpatialPad
        spatial_size: ${roi_size} # pad to at least the roi size
        mode: 'constant' # padding mode
        constant_values: 0 # padding value
      - type: Orientation
        axcodes: 'RAS' # orientation codes for the image, RAS is standard for medical images
      - type: AsDiscreteLabel
        argmax: false  # do not apply argmax, since label is not one-hot encoded
        to_onehot: ${num_classes}  # do not convert to one-hot encoding, since label is not one-hot encoded
        include_background: true  # include background class in the discretization
      - type: Spacing
        pixdim: ${spacing} # pixel dimensions for the image
        mode: ['bilinear', 'bilinear'] # can only use bilinear on label if one-hot encoded
        align_corners: null # align corners for the interpolation, set to null for default behavior
      - type: AsDiscreteLabel
        argmax: true  # do not apply argmax, since label is not one-hot encoded
        to_onehot: null  # do not convert to one-hot encoding, since label is not one-hot encoded
        include_background: true  # include background class in the discretization
      - type: RandSpatialCrop
        roi_size: ${roi_size} # crop size for training
        random_size: false # use fixed size for cropping
        random_center: true # use random center for cropping
      - type: RandFlip
        prob: 0.5 # probability of flipping the image
        spatial_axis: 0 # axes to flip the image
      - type: RandFlip
        prob: 0.5 # probability of flipping the image
        spatial_axis: 1 # axes to flip the image
      - type: RandFlip
        prob: 0.5 # probability of flipping the image
        spatial_axis: 2 # axes to flip the image
      - type: NormalizeIntensity
        nonzero: true # normalize only non-zero values
        channel_wise: true # normalize each channel separately
        subtrahend: null # subtrahend for normalization
        divisor: null # divisor for normalization
      - type: RandGaussianNoise
        prob: 0.2 # probability of applying the Gaussian noise
        mean: 0.0 # mean of the Gaussian noise
        std: 0.1 # standard deviation of the Gaussian
      - type: RandGaussianSmooth
        prob: 0.2 # probability of applying the Gaussian smoothing
        sigma_x: [0.5, 1.5] # standard deviation in x direction
        sigma_y: [0.5, 1.5] # standard deviation in y direction
        sigma_z: [0.5, 1.5] # standard deviation in z direction
      - type: RandScaleIntensity
        prob: 1.0 # probability of scaling the intensity
        # 0.1 means beween 0.9 and 1.1
        factors: 0.1 # scaling factors for the intensity
      - type: RandShiftIntensity
        prob: 1.0 # probability of shifting the intensity
        # 0.1 means beween -0.1 and 0.1
        offsets: 0.1 # shifting offsets for the intensity
      - type: RandAdjustContrast
        prob: 0.2 # probability of adjusting the contrast
        gamma: [0.7, 1.5] # gamma values for contrast adjustment
        invert_image: false
      - type: RandAdjustContrast
        prob: 0.2 # probability of adjusting the contrast
        gamma: [0.7, 1.5] # gamma values for contrast adjustment
        invert_image: true
    val:  # validation transforms
      - type: MapLabelValue # to exclude specified labels by mapping them to background
        orig_labels:   ${dataset.orig_labels}
        target_labels: ${dataset.target_labels}
      - type: EnsureChannelFirst  # not actually necessary for single-modal data
        channel_dim: no_channel  # to automatically add channel dimension if not present
      - type: SpatialPad
        spatial_size: ${roi_size} # pad to at least the roi size
        mode: 'constant' # padding mode
        constant_values: 0 # padding value
      - type: Orientation
        axcodes: 'RAS' # orientation codes for the image, RAS is standard for medical images
      - type: AsDiscreteLabel
        argmax: false  # do not apply argmax, since label is not one-hot encoded
        to_onehot: ${num_classes}  # do not convert to one-hot encoding, since label is not one-hot encoded
        include_background: true  # include background class in the discretization
      - type: Spacing
        pixdim: ${spacing} # pixel dimensions for the image
        mode: ['bilinear', 'bilinear'] # can only use bilinear on label if one-hot encoded
        align_corners: null # align corners for the interpolation, set to null for default behavior
      - type: AsDiscreteLabel
        argmax: true  # do not apply argmax, since label is not one-hot encoded
        to_onehot: null  # do not convert to one-hot encoding, since label is not one-hot encoded
        include_background: true  # include background class in the discretization
      - type: NormalizeIntensity
        nonzero: true # normalize only non-zero values
        channel_wise: true # normalize each channel separately
        subtrahend: null # subtrahend for normalization
        divisor: null # divisor for normalization

loss:
  type: monai # loss type
  _target_: monai.losses.DeepSupervisionLoss
  loss:
    _target_: monai.losses.DiceCELoss
    squared_pred: true
    to_onehot_y: true  # target is already one-hot encoded
    softmax: true
    sigmoid: false
    include_background: true # include background class in the loss calculation
    smooth_nr: 0
    smooth_dr: 1.0e-05


optimizer:
  _target_: torch.optim.AdamW
  lr: ${learning_rate} # base learning rate for the optimizer
  weight_decay: 1.0e-5 # weight decay for the optimizer

lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  T_0: 100
  eta_min: 0

handlers:
  train:
    - _target_: monai.handlers.CheckpointSaver
      _convert_: partial
      _requires_: [save_dict, save_dir]
      save_final: true
      final_filename: "final_model.pth"
      save_key_metric: false
      epoch_level: true
      save_interval: 5
      n_saved: 1
    - _target_:  monai.handlers.LrScheduleHandler
      _requires_: lr_scheduler
      print_lr: true
      epoch_level: true # step the scheduler at the end of the epoch if true, else every iteration
    - _target_: monai.handlers.ValidationHandler
      _requires_: validator
      interval: ${eval_every_epochs} # validate every epoch
      epoch_level: true # validate at the end of each epoch
      exec_at_start: true
    - _target_: monai.handlers.StatsHandler
      iteration_log: ${log_every_iters}
      epoch_log: false
      tag_name: "train loss"
    - _target_: monai.handlers.TensorBoardStatsHandler
      _requires_: [summary_writer]
      iteration_log: ${log_every_iters}
      epoch_log: true
      tag_name: "Train Loss"
    - _target_: ignite.handlers.ProgressBar
      desc: "Training"
    # NOTE: ignite also offers a terminate on nan handler, could be interesting
      
