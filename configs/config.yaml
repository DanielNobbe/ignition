seed: 777 # random seed
batch_size: 48 # train batch size
eval_batch_size: 32 # evaluation batch size
num_workers: 10 # number of subprocesses to use for data loading
max_epochs: 100 # number of maximum epochs
use_amp: false # use AMP (Automatic Mixed Precision)
debug: false
train_epoch_length: null
eval_epoch_length: null
filename_prefix: training
n_saved: 2
save_every_iters: 1000
patience: 5
output_dir: ./logs
log_every_iters: 10
lr: 0.02 # learning rate
accumulation_steps: 1 # parameter for gradient accumulation
eval_every_epochs: 10 # evaluate every n epochs
num_classes: 21 # number of classes for segmentation
backend: gloo
task: segmentation # task type
model:
  type: torchvision # model type
  name: deeplabv3_mobilenet_v3_large # model name
  pretrained: true # use pretrained weights
dataset:
  type: VOCSegmentationPairedDataset # dataset type
  root: /Users/daniel/data/ # dataset root path
  download: false # download the dataset if not present
  subset_size: 0.1 # subset size for the dataset, 0.1 means 10% of the data. If set to null, the full dataset is used
  train:
    img_size: 480 # image size for training
  val:
    img_size: 513 # image size for validation
  # TODO: These could also be part of transform settings
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225] # normalization values for the dataset
  # datasets:
  #   train:
  #     type: VOCSegmentation # dataset type, does not matter if paired dataset type is specified
  #     root: /Users/daniel/data/VOCdevkit # dataset root path
  #     download: true # download the dataset if not present
loss:
  type: CrossEntropyLoss # loss type
  ignore_index: 255 # index to ignore in the loss calculation. Use -100 for default PyTorch behavior
  label_smoothing: 0.0
lr_scheduler:
  type: PolynomialLR # learning rate scheduler type
  power: 0.8 # power for the polynomial decay
optimizer:
  type: SGD
  lr: 0.08 # base learning rate for the optimizer
  momentum: 0.8 # momentum for the optimizer
  weight_decay: 0 #5.0e-4 # weight decay for the optimizer
  nesterov: false # use Nesterov momentum
metrics:
  eval:
    type: SegmentationMetrics # evaluation metrics type
    iou: true # use IoU metric
    mIoU: true # use mean IoU metric
    background_index: 0 # ignore background class in IoU calculation, set to negative/null to disable
    best_metric_name: mIoU # name of the best metric to track for early stopping and checkpointing
  train:
    type: LossMetric # training metrics type
list_config:
  - name: "mIoU"
    type: "SegmentationMetrics"
    iou: true
    mIoU: true
    background_index: 0
    best_metric_name: mIoU
  - name: "loss"
    type: "LossMetric"
    ignore_index: 255 # index to ignore in the loss calculation. Use -100 for default PyTorch behavior
    label_smoothing: 0.0
  - name: "accuracy"
    type: "AccuracyMetric"
    top_k: 1 # top-k accuracy, set to 1 for standard accuracy
  - name: "precision"
    type: "PrecisionMetric"
    average: "macro" # macro, micro, or weighted average for precision