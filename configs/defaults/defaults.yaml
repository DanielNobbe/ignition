#@package _global_
mode: train
debug: false
seed: 777 # random seed
output_dir: ./logs
output_prefix: ${name}
task: segmentation # task type, only supports segmentation for now
inferer:  # set to null to disable sliding window inference
  _target_: monai.inferers.SlidingWindowInferer
  roi_size: ${roi_size} # roi size for inference
  sw_batch_size: ${eval_batch_size} # sliding window batch size
  overlap: 0.25
  mode: 'constant' # blending mode, can be 'constant' or 'gaussian'
  sigma_scale: 0.125 # scale for gaussian blending, only used if mode is 'gaussian'
  progress: true # show progress bar during inference

dataset:
  transforms:
    train:
    - type: EnsureChannelFirst
      channel_dim: no_channel  # to automatically add channel dimension if not present
    - type: Orientation
      axcodes: 'RAS' # orientation codes for the image, RAS is standard for medical images
    - type: RandSpatialCrop
      roi_size: ${roi_size} # crop size for training
      random_size: false # use fixed size for cropping
      random_center: true # use random center for cropping
    - type: NormalizeIntensity
      nonzero: true # normalize only non-zero values
      channel_wise: true # normalize each channel separately
      subtrahend: null # subtrahend for normalization
      divisor: null # divisor for normalization
    val:  # validation transforms
      - type: EnsureChannelFirst  # not actually necessary for single-modal data
        channel_dim: no_channel  # to automatically add channel dimension if not present
      - type: Orientation
        axcodes: 'RAS' # orientation codes for the image, RAS is standard for medical images
      - type: NormalizeIntensity
        nonzero: true # normalize only non-zero values
        channel_wise: true # normalize each channel separately
        subtrahend: null # subtrahend for normalization
        divisor: null # divisor for normalization
post_transforms:
  train: null  # could perhaps do the keeplargestconnectedcomponent
  val:  # TODO: Check if model already does a softmax? may need to add activation here
    _target_: monai.transforms.Compose
    transforms:
      - _target_: monai.transforms.Activationsd
        keys: ['pred']  # keys to apply the activation to
        softmax: true
      - _target_: monai.transforms.AsDiscreted
        keys: ['pred']  # keys to apply the discretization to
        argmax: true  # apply argmax to the predictions
        to_onehot: ${num_classes}  # convert to one-hot encoding  -- already one-hot from output
        include_background: true  # include background class in the discretization
        # keepdims: true
        # maybe we need a threshold here? or still argmax?
      - _target_: monai.transforms.AsDiscreted
        keys: ['label']  # keys to apply the discretization to
        argmax: false  # apply argmax to the predictions
        to_onehot: ${num_classes}  # convert to one-hot encoding
        include_background: true  # include background class in the discretization
        # it seems the label is not one-hot encoded, but we also don't need to argmax, since there is a threshold already. But we don't need that either

metrics:
  val:  # by default, the first metric is used as the 'key' metric
    - _target_: monai.handlers.MeanDice
      _key_: mean_dice
      include_background: true
      output_transform: 
        _target_: monai.handlers.from_engine
        keys: ['pred', 'label']  # keys to extract from the output
    - _target_: monai.handlers.MeanIoUHandler
      _key_: mean_iou
      include_background: true
      output_transform: 
        _target_: monai.handlers.from_engine
        keys: ['pred', 'label']  # keys to extract from the output
    - _target_: monai.handlers.ConfusionMatrix
      _key_: conf_matrix  # TODO: Implement conf matrix with all metrics
      metric_name: "f1 score"
      include_background: true
      output_transform:
        _target_: monai.handlers.from_engine
        keys: ['pred', 'label']  # keys to extract from the output
  train:
    - _target_: monai.handlers.IgniteMetricHandler
      _key_: train_loss
      _requires_: loss_fn
      output_transform:
        _target_: monai.handlers.from_engine
        keys: ['pred', 'label']  # keys to extract from the output, not sure why we can't just use 'loss' here
  val_key_metric_name: ${metrics.val[0]._key_} # name of the key metric for validation, used for early stopping and checkpointing
  train_key_metric_name: ${metrics.train[0]._key_} # name of the key metric for training, used for logging